{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартные библиотеки Python : \n",
    "os, sys, collections и другие являются мощным инструментом, которым нужно и полезно уметь пользоваться. \n",
    "\n",
    "Ресурсы к ознакомлению:\n",
    "\n",
    "sys -- https://docs.python.org/3/library/sys.html\n",
    "\n",
    "os -- https://docs.python.org/3/library/os.html\n",
    "\n",
    "collections -- https://docs.python.org/3/library/collections.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COLLECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque\n",
      "defaultdict\n",
      "OrderedDict\n",
      "namedtuple\n",
      "Counter\n",
      "ChainMap\n",
      "UserDict\n",
      "UserList\n",
      "UserString\n"
     ]
    }
   ],
   "source": [
    "from IPython.testing.tools import full_path\n",
    "\n",
    "\"\"\"\n",
    "    Начнем с collections. Библиотека хранит в себе специальные контейнеры, \n",
    "    расширяющие классический список контейнеров: списков, кортежей и словарей.\n",
    "\"\"\"\n",
    "import collections\n",
    "\"\"\"\n",
    "    Посмотреть содержащиеся полезные модули можно, написав функцию ниже одной строкой.\n",
    "\"\"\"\n",
    "print('\\n'.join(list(filter(lambda x: not x.startswith('_') and x != 'abc', collections.__dict__.keys()))))\n",
    "# содержательно эта строка станет понятна по мере освоения курса\n",
    "# она неявно содержит в себе концепции list comprehension, а также парадигмы функционального программирования\n",
    "# и в целом демонстрирует лаконичность и эффективность инструментов языка python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallOption(strike=100, expiration_date='2026-01-01') <class '__main__.CallOption'>\n",
      "100 <class 'int'> 2026-01-01 <class 'str'>\n",
      "Достаем словарь: {'strike': 100, 'expiration_date': '2026-01-01'} <class 'dict'>\n",
      "Создаем новый именованный кортеж: CallOption(strike=200, expiration_date='2026-01-01')\n",
      "('strike', 'expiration_date') <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Начнем с рассмотрения namedtuple. Это именованный кортеж, который то же самое, что и кортеж,\n",
    "    но допускает обращение к своим полям по имени. Более точно, это специальный тип класса с реализованным дандер методом '__repr__()'\n",
    "'''\n",
    "from collections import namedtuple\n",
    "from typing import NamedTuple # нужна для указания типа, или в качестве указания как родительского класса при создании дочернего\n",
    "\n",
    "CallOption = namedtuple('CallOption', ['strike', 'expiration_date'])\n",
    "\n",
    "my_option: CallOption = CallOption(strike=100, expiration_date='2026-01-01')\n",
    "print(my_option, type(my_option))\n",
    "print(my_option.strike, type(my_option.strike), my_option.expiration_date, type(my_option.expiration_date))\n",
    "\n",
    "# my_option.strike = 101 # AttributeError: can't set attribute\n",
    "'''\n",
    "    Для работы с именованными кортежами полезно пользоваться некоторыми методами\n",
    "'''\n",
    "# namedtuple._asdict() -- представляет объект класса как словарь\n",
    "print('Достаем словарь:', my_option._asdict(), type(my_option._asdict()))\n",
    "\n",
    "# namedtuple._replace -- возвращает новый экземляр  замененным полем\n",
    "print('Создаем новый именованный кортеж:', my_option._replace(strike=200))\n",
    "\n",
    "# namedtuple._fields -- получить кортеж строк полей\n",
    "print(my_option._fields, type(my_option._fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10) , ограничен по длине  10 \n",
      "\n",
      "Убрать элемент слева: 3 , в очереди останется: deque([4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10) , длина  9\n",
      "Убрать элемент справа: 12 , в очереди останется: deque([4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  8 \n",
      "\n",
      "Добавить элемент слева: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  9\n",
      "Добавить элемент справа: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11, 0], maxlen=10) , длина  10\n",
      "Добавить элемент слева: None , в очереди станет: deque([0, 0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  10\n",
      "Добавить элемент справа: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11, 0], maxlen=10) , длина  10\n",
      "Добавить еще элемент слева: None , в очереди станет: deque([0, 0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  10\n",
      "Добавить еще элемент слева: None , в очереди станет: deque([0, 0, 0, 4, 5, 6, 7, 8, 9, 10], maxlen=10) , длина  10\n",
      "deque([0, 0, 0, 4, 5, 6, 7, 8, 9, 10], maxlen=10) \n",
      "\n",
      "используем rotate(2): None , получаем: deque([9, 10, 0, 0, 0, 4, 5, 6, 7, 8], maxlen=10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Далее deque. Это список с эффективной реализацией добавления и извлечения элементов.\n",
    "    В соответствии с описанием в документации:\n",
    "        Дек это обобщение стека и очереди. Он потоко-безопасный (thread-safe, то есть его можно параллелить \n",
    "        на уровне потоков без опасения измененения объекта со стороны другого потока, здравствуй impute и lock),\n",
    "        эффективный по памяти и требует О(1) времени на добавление и извлечение элемента с начала и конца списка.\n",
    "\"\"\"\n",
    "from collections import deque\n",
    "\n",
    "my_deque = deque(maxlen=10)\n",
    "_ = [my_deque.append(i) for i in range(13)]\n",
    "print(my_deque, ', ограничен по длине ', len(my_deque), '\\n')\n",
    "\n",
    "print('Убрать элемент слева:', my_deque.popleft(), ', в очереди останется:', my_deque, ', длина ', len(my_deque))\n",
    "print('Убрать элемент справа:', my_deque.pop(), ', в очереди останется:', my_deque, ', длина ', len(my_deque), '\\n')\n",
    "\n",
    "print('Добавить элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "print('Добавить элемент справа:', my_deque.append(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "print('Добавить элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "print('Добавить элемент справа:', my_deque.append(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "print('Добавить еще элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "print('Добавить еще элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
    "'''\n",
    "    Очередь позволяет эффективно осуществлять операции вставки и изъятия объектов в начале и в конце списка.\n",
    "    И кроме того в ней встроена защита от дурака, которая не позволит создавать бесконечно большой список.\n",
    "'''\n",
    "print(my_deque * 2 ** 10, '\\n') # мы можем бесконечно долго из-за ошибки в коде нарашивать длину списка, но не сможем для очереди\n",
    "'''\n",
    "    deque поддерживает многие операции, доступные list:\n",
    "    insert, clear, copy, count, extend, remove, reverse\n",
    "    Есть свой метод rotate(n=1), который по принципу RR(RoundRobin) сдвигает все элементы на n вправо (n < 0 -- влево)\n",
    "'''\n",
    "print('используем rotate(2):', my_deque.rotate(2), ', получаем:', my_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_value\n",
      "missing_value\n",
      "arbitraty_value_inserted_right_here\n",
      "defaultdict(<class 'list'>, {'fridge': ['egg', 'steak', 'butter'], 'pocket': ['money']})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    следующий объект -- defaultdict. Он расширяет обыкновенный словарь, добавляя метод,\n",
    "    который вызывается каждый раз при отсуствии ключа, по которому произошло обращение. \n",
    "    При создании словаря с дефолтным значением в случае неуказания этого дефолтного значения (аргумент default_factory)\n",
    "    он работает как обычный словарь. Если default_factory указан, то по указанному отсутствующему ключу вызывается default_factory \n",
    "    Сигнатура такая : defaultdict(default_factory: Callable[[None], object])\n",
    "    При этом \n",
    "'''\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "my_default_dict = defaultdict()\n",
    "# my_default_dict['0'] # KeyError\n",
    "\n",
    "# 1 способ\n",
    "my_default_dict = defaultdict(lambda: 'missing_value')\n",
    "print(my_default_dict['0'])\n",
    "\n",
    "# 2 способ\n",
    "def return_dafault_value():\n",
    "    return 'missing_value'\n",
    "\n",
    "my_default_dict = defaultdict(return_dafault_value)\n",
    "print(my_default_dict['0'])\n",
    "\n",
    "# 3 способ\n",
    "def return_dafault_value(value):\n",
    "    return lambda: value\n",
    "\n",
    "my_default_dict = defaultdict(return_dafault_value('arbitraty_value_inserted_right_here'))\n",
    "print(my_default_dict['0'])\n",
    "\n",
    "# другие варианты\n",
    "my_default_dict = defaultdict(list) # дефолтом ставим список\n",
    "my_default_dict['fridge'].append('egg')\n",
    "my_default_dict['fridge'].append('steak')\n",
    "my_default_dict['fridge'].append('butter')\n",
    "my_default_dict['pocket'].append('money')\n",
    "print(my_default_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Упорядоченный словарь: OrderedDict([('a', None), ('b', None), ('c', None), ('d', None), ('e', None)]) <class 'collections.OrderedDict'>\n",
      "Переупорядочили ключи: acdeb\n",
      "Переупорядочили ключи сноав: bacde\n",
      "Текущий порядок: bacde , вытащим последний добавленный элемент (LIFO): ('e', None)\n",
      "Текущий порядок: bacd , вытащим первый добавленный элемент (FIFO): ('b', None)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    OrderedDict -- это словарь, который помнит порядок добавления ключей. Начиная с python 3.7 это умеет и дефолтный словарь (dict, не путать с defaultdict)\n",
    "    Так что по большому счету он не настолько актуален. Однако если вам нужно в явном виде донести важную идею вашего кода,\n",
    "    то использование OrderedDict оправдано вашими целями\n",
    "'''\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "my_ordered_dict: OrderedDict = OrderedDict.fromkeys('abcde')\n",
    "print('Упорядоченный словарь:', my_ordered_dict, type(my_ordered_dict))\n",
    "my_ordered_dict.move_to_end('b')\n",
    "print('Переупорядочили ключи:', ''.join(my_ordered_dict))\n",
    "\n",
    "my_ordered_dict.move_to_end('b', last=False)\n",
    "print('Переупорядочили ключи сноав:', ''.join(my_ordered_dict))\n",
    "\n",
    "print('Текущий порядок:', ''.join(my_ordered_dict), ', вытащим последний добавленный элемент (LIFO):', my_ordered_dict.popitem())\n",
    "print('Текущий порядок:', ''.join(my_ordered_dict), ', вытащим первый добавленный элемент (FIFO):', my_ordered_dict.popitem(last=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChainMap({'a': 1, 'b': 2, 'c': 3}, {'color': 'yellow', 'size': 10}, {'date': '2025-01-01', 'time': '16:00'}) <class 'collections.ChainMap'>\n",
      "Ссылаемся на объект из 3го словаря: 16:00\n",
      "date 2025-01-01\n",
      "time 16:00\n",
      "color yellow\n",
      "size 10\n",
      "a 1\n",
      "b 2\n",
      "c 3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    ChainMap -- подкласс словаря, который объединяет несколько отдельных словарей в один общий.\n",
    "'''\n",
    "\n",
    "from collections import ChainMap\n",
    "\n",
    "my_dict_1 = dict(a=1, b=2, c=3)\n",
    "my_dict_2 = dict(color='yellow', size=10)\n",
    "my_dict_3 = dict(date='2025-01-01', time='16:00')\n",
    "\n",
    "chain_map : ChainMap = ChainMap(my_dict_1, my_dict_2, my_dict_3)\n",
    "print(chain_map, type(chain_map))\n",
    "print('Ссылаемся на объект из 3го словаря:', chain_map['time'])\n",
    "# print('Ссылаемся на объект, которого нет:', chain_map['weather']) # KeyError\n",
    "# мы можем проитерироваться по всем объектам в chain'e\n",
    "for key, value in chain_map.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Счетчик: Counter({1: 4, 0: 3, 2: 2, 3: 2, 5: 1}) <class 'collections.Counter'>\n",
      "Два самых частых числа (число, кол-во): [(1, 4), (0, 3)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Последний рассматриваемый -- Counter -- объект, который парсит итерируемый объект на тему повторяющихся элементов\n",
    "    и формирует словарь, в котором ключами являются уникальные элементы входного списка, а значениями их количество.\n",
    "'''\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "my_counter : Counter = Counter([0,1,2,3,3,2,1,1,1,0,5,0])\n",
    "print('Счетчик:', my_counter, type(my_counter))\n",
    "\n",
    "# дополнительно можно посмотреть наиболее часто встречающиеся объекты\n",
    "print('Два самых частых числа (число, кол-во):', my_counter.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SYS and OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc, sys, st, GenericAlias, name, linesep, stat, access, chdir, chmod, getcwd, getcwdb, link, listdir, lstat, mkdir, readlink, rename, replace, rmdir, symlink, system, umask, unlink, remove, utime, times, execv, execve, spawnv, spawnve, getpid, getppid, getlogin, kill, startfile, waitpid, open, close, closerange, device_encoding, dup, dup2, lseek, read, write, fstat, isatty, pipe, ftruncate, truncate, putenv, unsetenv, strerror, fsync, abort, urandom, get_terminal_size, cpu_count, get_inheritable, set_inheritable, get_handle_inheritable, set_handle_inheritable, scandir, fspath, waitstatus_to_exitcode, environ, F_OK, R_OK, W_OK, X_OK, TMP_MAX, O_RDONLY, O_WRONLY, O_RDWR, O_APPEND, O_CREAT, O_EXCL, O_TRUNC, O_BINARY, O_TEXT, O_NOINHERIT, O_SHORT_LIVED, O_TEMPORARY, O_RANDOM, O_SEQUENTIAL, EX_OK, P_WAIT, P_NOWAIT, P_NOWAITO, P_OVERLAY, P_DETACH, error, stat_result, statvfs_result, terminal_size, DirEntry, times_result, uname_result, path, curdir, pardir, sep, pathsep, defpath, extsep, altsep, devnull, supports_dir_fd, supports_effective_ids, supports_fd, supports_follow_symlinks, SEEK_SET, SEEK_CUR, SEEK_END, makedirs, removedirs, renames, walk, execl, execle, execlp, execlpe, execvp, execvpe, get_exec_path, MutableMapping, Mapping, getenv, supports_bytes_environ, fsencode, fsdecode, spawnl, spawnle, popen, fdopen, PathLike, add_dll_directory\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    библиотека os позволяет работать с некоторым функционалом операционной системы, \n",
    "    которой вы пользуетесь. Как и ранее для более полного ознакомления со всем функционалом рекомендуется читать документацию.\n",
    "'''\n",
    "\n",
    "import os\n",
    "print(', '.join(list(filter(lambda x: not x.startswith('_'), os.__dict__.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = None\n",
    "\n",
    "# environ содержит словарь с переменными окружения\n",
    "os.environ\n",
    "\n",
    "# getlogin возвращает имя пользователя\n",
    "os.getlogin()\n",
    "\n",
    "# getpid getppid -- id процесса и id его родительского процесса\n",
    "os.getpid()\n",
    "os.getppid()\n",
    "\n",
    "# os.chmod(path, mode, ...) -- установить мод(режим) для файла по пути path\n",
    "\n",
    "# вернуть текущую директорию\n",
    "os.getcwd()\n",
    "\n",
    "# вернуть список файлов в директории\n",
    "os.listdir()\n",
    "\n",
    "# создает директорию по указанному пути path; \n",
    "# если аргумент 'exist_ok' = True , то функция в случае существования директории не поднимет ошибку, если False -- FileExistsError\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# remove / unlink удаляет файл по указанному пути; если указать директорию, будет выдана ошибка OSError\n",
    "os.remove(path) \n",
    "os.unlink(path)\n",
    "\n",
    "# remodirs удаляет директорию по указанному пути; в случае ошибки выдает OSError\n",
    "os.remodirs(path) \n",
    "\n",
    "# переименовать src файл/директорию в dst\n",
    "os.rename(src=None, dst=None)\n",
    "\n",
    "# scandir возвращает итератор объектов, расположенных по пути path\n",
    "os.scandir(path)\n",
    "\n",
    "# возвращает количество логических процессоров в системе\n",
    "os.cpu_count()\n",
    "\n",
    "#####     os.path     #####\n",
    "\n",
    "# abspath возвращает абсолютный путь к указанному относительному пути\n",
    "os.path.abspath('.')\n",
    "\n",
    "# вовзращает имя конечной точки указанного пути\n",
    "os.path.basename(path)\n",
    "\n",
    "# exists проверяет существование директории или файла по указанному пути и возрвращает True или False\n",
    "os.path.exists(path)\n",
    "\n",
    "# возвращают время\n",
    "os.path.getatime('.') # посещения файла/директории\n",
    "os.path.getmtime('.') # изменения файла/директории\n",
    "os.path.getctime('.') # создания файла/директории\n",
    "\n",
    "# вовзращает размер файла/директории в байтах\n",
    "os.path.getsize(path)\n",
    "\n",
    "# по-умному конкатенирует части путей в один\n",
    "os.path.join(path, *paths)\n",
    "\n",
    "# нормализует путь: удаляет ненужные/кривые символы\n",
    "os.path.normpath(path)\n",
    "\n",
    "# разбивает входную сроку-путь на (head, tail), tail последний файл/директория в пути\n",
    "os.path.split(path)\n",
    "\n",
    "# разбивает входную сроку-путь на путь и расширение файла\n",
    "os.path.splitext('somebody/once/told.me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addaudithook, audit, breakpointhook, displayhook, exception, exc_info, excepthook, exit, getdefaultencoding, getallocatedblocks, getfilesystemencoding, getfilesystemencodeerrors, getrefcount, getrecursionlimit, getsizeof, getwindowsversion, intern, is_finalizing, setswitchinterval, getswitchinterval, setprofile, getprofile, setrecursionlimit, settrace, gettrace, call_tracing, set_coroutine_origin_tracking_depth, get_coroutine_origin_tracking_depth, set_asyncgen_hooks, get_asyncgen_hooks, unraisablehook, get_int_max_str_digits, set_int_max_str_digits, modules, stderr, version, hexversion, api_version, copyright, platform, maxsize, float_info, int_info, hash_info, maxunicode, builtin_module_names, stdlib_module_names, byteorder, dllhandle, winver, version_info, implementation, flags, float_repr_style, thread_info, meta_path, path_importer_cache, path_hooks, path, executable, prefix, base_prefix, exec_prefix, base_exec_prefix, platlibdir, pycache_prefix, argv, orig_argv, warnoptions, dont_write_bytecode, stdin, stdout, ps1, ps2, ps3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    библиотека sys позволяет работать с некоторым функционалом интерпретатора.\n",
    "'''\n",
    "\n",
    "import sys\n",
    "print(', '.join(list(filter(lambda x: not x.startswith('_'), sys.__dict__.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argv возвращает аргументы скрипта, [0] элемент это имя файла скрипта\n",
    "sys.argv\n",
    "\n",
    "# содержит copyright\n",
    "sys.copyright\n",
    "\n",
    "# очищает кеш интерпретатора\n",
    "sys._clear_type_cache() # до python 3.13\n",
    "# sys._clear_internal_caches() # python 3.13+\n",
    "\n",
    "#  sys.exception() возвращает пойманную в 'except' ошибку; вне конструкции возвращает None (то есть ничего)\n",
    "try:\n",
    "    _ = 0 / 0\n",
    "except:\n",
    "    exception = sys.exception()\n",
    "    \n",
    "# возвращает SystemExit exception, сигнализирующий о завершении выполнения интерпретатора\n",
    "# sys.exit()\n",
    "\n",
    "# возвращает количество блоков памяти, занятых интерпретатором\n",
    "sys.getallocatedblocks()\n",
    "\n",
    "# возвращает предел рекурсии в интерпретаторе\n",
    "sys.getrecursionlimit()\n",
    "# sys.setrecursionlimit(N) # устанавливает лимит на рекурсию\n",
    "\n",
    "# возвращает размер объекта в байтах\n",
    "sys.getsizeof( 0 )\n",
    "\n",
    "# возвращает глубину вложенных корутин\n",
    "sys.get_coroutine_origin_tracking_depth()\n",
    "\n",
    "# список всех текущих модулей\n",
    "sys.modules.keys()\n",
    "\n",
    "# версия интерпретатора\n",
    "sys.version\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TYPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCMeta, AbstractSet, Annotated, Any, AnyStr, AsyncContextManager, AsyncGenerator, AsyncIterable, AsyncIterator, Awaitable, BinaryIO, ByteString, CT_co, Callable, ChainMap, ClassVar, Collection, Concatenate, Container, ContextManager, Coroutine, Counter, DefaultDict, Deque, Dict, EXCLUDED_ATTRIBUTES, Final, ForwardRef, FrozenSet, Generator, Generic, GenericAlias, Hashable, IO, ItemsView, Iterable, Iterator, KT, KeysView, List, Literal, LiteralString, Mapping, MappingView, Match, MethodDescriptorType, MethodWrapperType, MutableMapping, MutableSequence, MutableSet, NamedTuple, NamedTupleMeta, Never, NewType, NoReturn, NotRequired, Optional, OrderedDict, ParamSpec, ParamSpecArgs, ParamSpecKwargs, Pattern, Protocol, Required, Reversible, Self, Sequence, Set, Sized, SupportsAbs, SupportsBytes, SupportsComplex, SupportsFloat, SupportsIndex, SupportsInt, SupportsRound, T, TYPE_CHECKING, T_co, T_contra, Text, TextIO, Tuple, Type, TypeAlias, TypeAliasType, TypeGuard, TypeVar, TypeVarTuple, TypedDict, Union, Unpack, VT, VT_co, V_co, ValuesView, WrapperDescriptorType, abstractmethod, assert_never, assert_type, cast, clear_overloads, collections, contextlib, copyreg, dataclass_transform, defaultdict, final, functools, get_args, get_origin, get_overloads, get_type_hints, io, is_typeddict, no_type_check, no_type_check_decorator, operator, overload, override, re, reveal_type, runtime_checkable, stdlib_re, sys, types, warnings\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    В общем, строгая типизация и аннотирование вашего кода значительно упростят\n",
    "    всю дальнейшую работу с ним. Как вам, так и другим, кто будет его читать.\n",
    "'''\n",
    "\n",
    "import typing\n",
    "print(', '.join(sorted(list(filter(lambda x: not x.startswith('_'), typing.__dict__.keys())))))\n",
    "\n",
    "'''\n",
    "    Вам желательно запомнить некоторые наиболее часто употребляемые типы.\n",
    "    Касательно остальных было неплохо их хотя бы знать, чтобы при случае вы могли ими воспользоваться.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SERIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, default write! \n",
      "\n",
      "Hello, json! \n",
      "\n",
      "Hello, dill|pickle|cloudpickle! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "wikipedia\n",
    "    Сериализация (в программировании) — процесс перевода структуры данных в битовую последовательность. \n",
    "    Обратной к операции сериализации является операция десериализации (структуризации) — \n",
    "        создание структуры данных из битовой последовательности.\n",
    "    Мы будем ссылаться на сериализацию как на возможность создания и сохранения файла \n",
    "    из некоторого объекта python.\n",
    "    Есть несколько библиотек, которые позволяют сериализовать некоторый объект.\n",
    "    Если это dataframe, то его можно сериализовать в parquet, csv и другие форматы, предусмотренные библиотекой.\n",
    "    Если это некоторая строка, словарь, список -- можно использовать json\n",
    "    Если это какой-то произвольный объект (любой, в том числе и из вышеперечисленных) --\n",
    "        его можно сохранить в виде бинарного файла. Библиотеки: dill, cloudpickle, pickle\n",
    "        В реальности, разумно ограничиться одной библиотекой. Ознакомьтесь с каждой из списка выше\n",
    "'''\n",
    "\n",
    "import json, cloudpickle, pickle, dill\n",
    "\n",
    "# В общем случае, для работы с файлами используют контекстный менеджер with\n",
    "# Он гарантирует, что вне его блока кода файл корректно будет закрыт\n",
    "\n",
    "# default'ная запись и чтение текстового файла\n",
    "with open('somefile.txt', 'w') as file: # первый аргумент - имя файла, второй режим использования ('w' - запись, 'r' - чтение)\n",
    "    file.write('Hello, default write!')\n",
    "with open('somefile.txt', 'r') as file:\n",
    "    line = file.read()\n",
    "    print(line, '\\n')\n",
    "\n",
    "# сериализация с помощью json\n",
    "with open('somefile.json', 'w') as file:\n",
    "    json.dump('Hello, json!', file)\n",
    "with open('somefile.json', 'r') as file:\n",
    "    line = json.load(file)\n",
    "    print(line, '\\n')\n",
    "\n",
    "# сериализация с помощью dill, pickle, cloudpickle\n",
    "with open('somefile.pickle', 'wb') as file: # для бинарных файлов режим доступа нужно писать 'wb', 'rb' что значит 'binary'\n",
    "    dill.dump('Hello, dill|pickle|cloudpickle!', file)\n",
    "    pickle.dump('Hello, dill|pickle|cloudpickle!', file)\n",
    "    cloudpickle.dump('Hello, dill|pickle|cloudpickle!', file)\n",
    "with open('somefile.pickle', 'rb') as file:\n",
    "    line = dill.load(file)\n",
    "    line = pickle.load(file)\n",
    "    line = cloudpickle.load(file)\n",
    "    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n",
      "\n",
      "LinearRegression() LinearRegression()\n",
      "\n",
      "Defined function\n"
     ]
    }
   ],
   "source": [
    "# вы можете сериализовать почти любой объект и его состояние\n",
    "\n",
    "# class\n",
    "class ToDemonstrate:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def print_hello(self):\n",
    "        print('Hello, world!')\n",
    "\n",
    "my_class = ToDemonstrate()\n",
    "\n",
    "with open('demonstration_cls.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(my_class, f)\n",
    "with open('demonstration_cls.pkl', 'rb') as f:\n",
    "    new_read_class = cloudpickle.load(f)\n",
    "new_read_class.print_hello()\n",
    "print()\n",
    "\n",
    "# объект из библиотеки, например, объект линейной регресии, который тоже класс\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "with open('not_fitted_lr.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(lr, f)\n",
    "with open('not_fitted_lr.pkl', 'rb') as f:\n",
    "    new_read_lr = cloudpickle.load(f)\n",
    "print(lr, new_read_lr)\n",
    "print()\n",
    "\n",
    "# фунцию (но не анонимную lambda функцию!)\n",
    "def to_save():\n",
    "    print('Defined function')\n",
    "with open('my_func.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(to_save, f)\n",
    "with open('my_func.pkl', 'rb') as f:\n",
    "    new_read_func = cloudpickle.load(f)\n",
    "new_read_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЗАДАЧИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Ниже вам будут предложены задачи для освоения материалов.\n",
    "    Собственно, первая и параллельная задача:\n",
    "        Все объекты, которые вы создадите нужно упаковать в виде файлов (то есть сериализовать).\n",
    "        По расширению файла должно быть понятно, как его прочитать.\n",
    "        Дополнительно вам нужно узнать как сохранять файлы в формате .rar, .zip, .tar.gz \n",
    "            и тоже сохранить файлы в этих форматах.\n",
    "\n",
    "    Требования к написанию кода: структура, читаемость, строгая типизация и аннотирования.\n",
    "    Код должен быть очевиден, понятен, структурирован.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте простую модель стоянки. \n",
    "# 1) Скажем, ваши автомобили это именованные кортежи, с указанием марки автомобиля, модели, гос.номера и цвета\n",
    "# 2) Сама стоянка это двусторонняя очередь (deque)\n",
    "#   Представим, что у нас нет коллизий, и если места на стоянке нет, то виртуально вызывается эвакуатор и убирает самый крайний автомобиль (как и работает deque)\n",
    "# 3) Создайте набор автомобилей и в случайном порядке добавляйте/удаляйте их с автостоянки.\n",
    "# 4) Посчитайте, сколько и каких автомобилей осталось на автостоянке.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T08:07:05.638462Z",
     "start_time": "2025-09-25T08:07:05.612887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "from collections import deque, namedtuple\n",
    "import random\n",
    "\n",
    "Car = namedtuple('Car', ['marka', 'model', 'id', 'color'])\n",
    "Parking = deque(maxlen=10)\n",
    "\n",
    "def park_car(car: namedtuple, parking: deque)-> None:\n",
    "    parking.append(car)\n",
    "\n",
    "def unpark_car(car: namedtuple, parking: deque)-> None:\n",
    "    if car in parking:\n",
    "        parking.remove(car)\n",
    "\n",
    "def count_cars(parking: deque)-> int:\n",
    "    return len(parking)\n",
    "\n",
    "\n",
    "cars = [\n",
    "    Car(\"Toyota\", \"Camry\", \"A123BC\", \"красный\"),\n",
    "    Car(\"BMW\", \"X5\", \"B456DE\", \"синий\"),\n",
    "    Car(\"Mercedes\", \"E-Class\", \"C789FG\", \"черный\"),\n",
    "    Car(\"Audi\", \"A4\", \"D012HI\", \"белый\"),\n",
    "    Car(\"Honda\", \"Civic\", \"E345JK\", \"зеленый\"),\n",
    "    Car(\"Ford\", \"Focus\", \"F678LM\", \"серый\"),\n",
    "    Car(\"Volkswagen\", \"Golf\", \"G901NO\", \"желтый\"),\n",
    "    Car(\"Hyundai\", \"Solaris\", \"H234PQ\", \"серебристый\"),\n",
    "    Car(\"Kia\", \"Rio\", \"I567RS\", \"коричневый\"),\n",
    "    Car(\"Nissan\", \"Qashqai\", \"J890TU\", \"оранжевый\"),\n",
    "    Car(\"Skoda\", \"Octavia\", \"K123VW\", \"фиолетовый\"),\n",
    "    Car(\"Lada\", \"Vesta\", \"L456XY\", \"бордовый\")\n",
    "]\n",
    "\n",
    "for i in range(5):\n",
    "    car = random.choice(cars)\n",
    "    park_car(car, Parking)\n",
    "\n",
    "operations = ['park', 'unpark']\n",
    "for i in range(20):\n",
    "    operation = random.choice(operations)\n",
    "    car = random.choice(cars)\n",
    "\n",
    "    if operation == 'park':\n",
    "        park_car(car, Parking)\n",
    "    else:\n",
    "        unpark_car(car, Parking)\n",
    "\n",
    "print(f\"Всего автомобилей на стоянке: {count_cars(Parking)}\")\n",
    "\n",
    "\n",
    "print(\"Список автомобилей на стоянке:\")\n",
    "for i, car in enumerate(Parking, 1):\n",
    "    print(f\"{i}. {car.marka} {car.model} ({car.id}), цвет: {car.color}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего автомобилей на стоянке: 1\n",
      "Список автомобилей на стоянке:\n",
      "1. Hyundai Solaris (H234PQ), цвет: серебристый\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь вы работаете в роли архивариуса РСФСР и занимаетесь хранением информации об иуществе раскулаченных граждан Имперской России\n",
    "# У вас несколько книг с записями, упорядоченных по алфавиту. Каждая книга хранит фамилии, начинающиеся с конкретной буквы.\n",
    "# Внутри книги указаны фамилии, к каждому гражданину указана категория имущества, например, мебель, посуда, картины и т.д.\n",
    "# В каждой категории указан список вещей, которые были изъяты. \n",
    "# Вы вносите записи, и если новой записи нет, вы ее создаете. Затем, когда ищите конкретную категорию предмета, начинаете перебирать все книги, начиная с первой буквы по алфавиту в вашем списке.\n",
    "# Очевидно, что вам нужно использовать defaultdict и ChainMap\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T11:19:47.874777Z",
     "start_time": "2025-09-25T11:19:47.849378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict, ChainMap\n",
    "from typing import List\n",
    "\n",
    "# --- Архивы ---\n",
    "Archive_by_surname = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "Archive_by_category = defaultdict(lambda: defaultdict(list))\n",
    "Full_archive = ChainMap(*Archive_by_surname.values())\n",
    "\n",
    "# --- Добавление записи ---\n",
    "def add_staff(surname: str, category: str, staff: List[str]) -> None:\n",
    "    first_letter = surname[0].upper()\n",
    "    for item in staff:\n",
    "        # По фамилиям\n",
    "        if item not in Archive_by_surname[first_letter][surname][category]:\n",
    "            Archive_by_surname[first_letter][surname][category].append(item)\n",
    "        # По категориям\n",
    "        if item not in Archive_by_category[category][surname]:\n",
    "            Archive_by_category[category][surname].append(item)\n",
    "\n",
    "\n",
    "def show_all_archive():\n",
    "    print(\"Архив по буквам:\")\n",
    "    for letter, surnames in Archive_by_surname.items():\n",
    "        print(f\"\\nКнига {letter}:\")\n",
    "        for surname, categories in surnames.items():\n",
    "            print(f\"  {surname}:\")\n",
    "            for category, items in categories.items():\n",
    "                print(f\"    {category}: {items}\")\n",
    "\n",
    "def show_by_surname(surname: str):\n",
    "    try:\n",
    "        record = Full_archive[surname]\n",
    "        print(f\"{surname}:\")\n",
    "        for category, items in record.items():\n",
    "            print(f\"  {category}: {items}\")\n",
    "    except KeyError:\n",
    "        print(f\"Фамилия '{surname}' не найдена в архиве.\")\n",
    "\n",
    "\n",
    "def show_by_category(category: str):\n",
    "    try:\n",
    "        records = Archive_by_category[category]\n",
    "        print(f\"Категория '{category}':\")\n",
    "        for surname, items in records.items():\n",
    "            print(f\"  {surname}: {items}\")\n",
    "    except KeyError:\n",
    "        print(f\"Категория '{category}' не найдена в архиве.\")\n",
    "\n",
    "#Тестовые данные\n",
    "add_staff(\"Иванов\", \"мебель\", [\"дубовый стол\", \"венский стул\"])\n",
    "add_staff(\"Иванов\", \"посуда\", [\"серебряный сервиз\"])\n",
    "add_staff(\"Петров\", \"мебель\", [\"кожаный диван\", \"кресло-качалка\"])\n",
    "add_staff(\"Петров\", \"драгоценности\", [\"серебряные запонки\"])\n",
    "add_staff(\"Сидоров\", \"картины\", [\"портрет неизвестного\"])\n",
    "add_staff(\"Алексеев\", \"мебель\", [\"кровать двуспальная\", \"тумба прикроватная\"])\n",
    "add_staff(\"Кузнецов\", \"посуда\", [\"медный самовар\"])\n",
    "\n",
    "show_all_archive()        # весь архив по буквам\n",
    "show_by_surname(\"Иванов\") # имущество Иванова\n",
    "show_by_category(\"мебель\")# все владельцы мебели\n",
    "show_by_surname(\"Смирнов\")# фамилия которой нет (KeyError обработан)\n",
    "show_by_category(\"книги\") # категория которой нет (KeyError обработан)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архив по буквам:\n",
      "\n",
      "Книга И:\n",
      "  Иванов:\n",
      "    мебель: ['дубовый стол', 'венский стул']\n",
      "    посуда: ['серебряный сервиз']\n",
      "\n",
      "Книга П:\n",
      "  Петров:\n",
      "    мебель: ['кожаный диван', 'кресло-качалка']\n",
      "    драгоценности: ['серебряные запонки']\n",
      "\n",
      "Книга С:\n",
      "  Сидоров:\n",
      "    картины: ['портрет неизвестного']\n",
      "\n",
      "Книга А:\n",
      "  Алексеев:\n",
      "    мебель: ['кровать двуспальная', 'тумба прикроватная']\n",
      "\n",
      "Книга К:\n",
      "  Кузнецов:\n",
      "    посуда: ['медный самовар']\n",
      "Фамилия 'Иванов' не найдена в архиве.\n",
      "Категория 'мебель':\n",
      "  Иванов: ['дубовый стол', 'венский стул']\n",
      "  Петров: ['кожаный диван', 'кресло-качалка']\n",
      "  Алексеев: ['кровать двуспальная', 'тумба прикроватная']\n",
      "Фамилия 'Смирнов' не найдена в архиве.\n",
      "Категория 'книги':\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя sys и os \n",
    "# Выведите некоторые ваши директории с указанием размера всех файлов и упорядочьте их (директории) по времени последнего обращения\n",
    "# Выведите список расширений файлов, которые хранятся на вашем ПК\n",
    "# Посчитайте объем памяти, который используется вашим интерпретатором\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:37:35.559276Z",
     "start_time": "2025-09-25T16:37:34.620477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "import psutil\n",
    "from collections import namedtuple\n",
    "\n",
    "DirInfo = namedtuple('DirInfo', ['name', 'last_call', 'size'])\n",
    "\n",
    "\n",
    "def my_dirs(path: str)->list[DirInfo]:\n",
    "    all_info: list[DirInfo] = []\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_dir():\n",
    "                total:int=0\n",
    "                for f in os.scandir(entry.path):\n",
    "                    if f.is_file():\n",
    "                        total+=f.stat().st_size\n",
    "                info = DirInfo(name=entry.name, last_call=entry.stat().st_atime, size=total)\n",
    "                all_info.append(info)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Такого пути не найдено\")\n",
    "    return sorted(all_info, key = lambda x: x.last_call)\n",
    "\n",
    "\n",
    "extensions: set[str] = set()\n",
    "def set_of_extensions(path: str)->None:\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file():\n",
    "                e=os.path.splitext(entry.name)[1]\n",
    "                if e:\n",
    "                    extensions.add(e)\n",
    "            else:\n",
    "                set_of_extensions(entry.path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Такого пути не найдено\")\n",
    "# Путь, который хотим проверить\n",
    "path = \"C:\\\\Users\\\\russkievpered\\\\Desktop\\\\dev\\\\proj_1\"\n",
    "\n",
    "dirs_info = my_dirs(path)\n",
    "print(\"Директории (имя, время последнего доступа, суммарный размер файлов):\")\n",
    "for d in dirs_info:\n",
    "    print(d)\n",
    "\n",
    "\n",
    "set_of_extensions(path)\n",
    "print(\"\\nРасширения файлов в директории и подпапках:\")\n",
    "print(sorted(extensions))\n",
    "\n",
    "\n",
    "import psutil, os\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_in_mb: float = process.memory_info().rss / 1024 / 1024\n",
    "print(f\"\\nОбъём памяти интерпретатора: {memory_in_mb:.2f} МБ\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директории (имя, время последнего доступа, суммарный размер файлов):\n",
      "DirInfo(name='logs', last_call=1758787005.6727138, size=1465)\n",
      "DirInfo(name='.idea', last_call=1758787005.673711, size=4287)\n",
      "DirInfo(name='python', last_call=1758787005.673711, size=0)\n",
      "DirInfo(name='.git', last_call=1758794792.15536, size=15423)\n",
      "\n",
      "Расширения файлов в директории и подпапках:\n",
      "['.TAG', '.bat', '.cfg', '.dll', '.exe', '.fish', '.iml', '.ipynb', '.json', '.log', '.md', '.nu', '.pem', '.pkl', '.ps1', '.pth', '.py', '.pyc', '.pyd', '.sample', '.swp', '.txt', '.typed', '.virtualenv', '.xml']\n",
      "\n",
      "Объём памяти интерпретатора: 23.11 МБ\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ДОПОЛНИТЕЛЬНЫЕ ПРАКТИЧЕСКИЕ ЗАДАЧИ\n",
    "\n",
    "Ниже представлены дополнительные задачи для закрепления изученного материала. Каждая задача использует только те концепции, которые были представлены в данном уроке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1: Система управления библиотекой**\n",
    "\n",
    "Создайте систему управления библиотекой используя collections:\n",
    "\n",
    "1. Создайте namedtuple `Book` с полями: title, author, isbn, year\n",
    "2. Создайте namedtuple `Reader` с полями: name, reader_id, phone\n",
    "3. Используйте `defaultdict(list)` для хранения книг по жанрам\n",
    "4. Используйте `deque` для очереди читателей, ожидающих популярную книгу\n",
    "5. Используйте `Counter` для подсчета количества книг каждого автора\n",
    "6. Используйте `OrderedDict` для хранения истории выдачи книг (читатель -> список книг)\n",
    "7. Сериализуйте все данные в JSON и pickle форматы\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T21:59:12.580810Z",
     "start_time": "2025-09-24T21:59:12.536981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pickle\n",
    "from collections import namedtuple, defaultdict, deque, Counter, OrderedDict\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "Book = namedtuple('Book', ['title', 'author', 'isbn', 'year'])\n",
    "Reader = namedtuple('Reader', ['name', 'reader_id', 'phone'])\n",
    "\n",
    "def create_library_data() -> Dict[str, Any]:\n",
    "    books = [\n",
    "        Book('Война и мир', 'Толстой', '123456', 1869),\n",
    "        Book('Анна Каренина', 'Толстой', '654321', 1877),\n",
    "        Book('Преступление и наказание', 'Достоевский', '111222', 1866),\n",
    "        Book('Идиот', 'Достоевский', '333444', 1869),\n",
    "        Book('Мастер и Маргарита', 'Булгаков', '555666', 1967),\n",
    "    ]\n",
    "\n",
    "    readers = [\n",
    "        Reader('Иван Иванов', 1, '+79991234567'),\n",
    "        Reader('Мария Петрова', 2, '+79997654321'),\n",
    "        Reader('Сергей Сидоров', 3, '+79999887766'),\n",
    "    ]\n",
    "\n",
    "    library = defaultdict(list)\n",
    "    library['Роман'].extend([books[0], books[1]])\n",
    "    library['Классика'].extend([books[2], books[3]])\n",
    "    library['Фантастика'].append(books[4])\n",
    "\n",
    "    reader_queue = deque([readers[1], readers[2]])  # читатели в очереди\n",
    "\n",
    "    author_counter = Counter(book.author for book in books)\n",
    "\n",
    "    history = OrderedDict()\n",
    "    history[readers[0]] = [books[3]]\n",
    "    history[readers[1]] = [books[1], books[2]]\n",
    "\n",
    "    return {\n",
    "        'books': books,\n",
    "        'readers': readers,\n",
    "        'library': library,\n",
    "        'reader_queue': reader_queue,\n",
    "        'author_counter': author_counter,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "def save_library_data(data: Dict[str, Any]) -> None:\n",
    "    try:\n",
    "        with open('library.json', 'w', encoding='utf-8') as f:\n",
    "            json_data = {\n",
    "                'books': [b._asdict() for b in data['books']],\n",
    "                'readers': [r._asdict() for r in data['readers']],\n",
    "                'library': {k: [b._asdict() for b in v] for k, v in data['library'].items()},\n",
    "                'reader_queue': [r._asdict() for r in data['reader_queue']],\n",
    "                'author_counter': dict(data['author_counter']),\n",
    "                'history': {r.name: [b._asdict() for b in blist] for r, blist in data['history'].items()}\n",
    "            }\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "        print(\"Данные сохранены в library.json\")\n",
    "\n",
    "        with open('library.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(\"Данные сохранены в library.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении: {e}\")\n",
    "\n",
    "data = create_library_data()\n",
    "save_library_data(data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные сохранены в library.json\n",
      "Данные сохранены в library.pkl\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2: Анализатор файловой системы**\n",
    "\n",
    "Создайте анализатор файловой системы используя os и sys:\n",
    "\n",
    "1. Создайте namedtuple `FileInfo` с полями: name, size, extension, modified_time\n",
    "2. Используйте `os.walk()` для обхода директории\n",
    "3. Используйте `os.path` функции для получения информации о файлах\n",
    "4. Используйте `Counter` для подсчета файлов по расширениям\n",
    "5. Используйте `defaultdict(list)` для группировки файлов по размеру (маленькие < 1MB, средние 1-100MB, большие > 100MB)\n",
    "6. Используйте `deque` для хранения последних 10 найденных файлов\n",
    "7. Выведите статистику используя `sys.getsizeof()` для подсчета памяти\n",
    "8. Сохраните результаты в JSON файл\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T22:08:03.558586Z",
     "start_time": "2025-09-24T22:08:03.527799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import namedtuple, Counter, defaultdict, deque\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "FileInfo = namedtuple('FileInfo', ['name', 'size', 'extension', 'modified_time'])\n",
    "\n",
    "def analyze_directory(path: str) -> Dict[str, Any]:\n",
    "    all_files: List[FileInfo] = []\n",
    "    try:\n",
    "        for dirpath, _, filenames in os.walk(path): #игнорируем список подпапок\n",
    "            for filename in filenames:\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    file_info = FileInfo(\n",
    "                        name=filename,\n",
    "                        size=os.path.getsize(full_path),\n",
    "                        extension=os.path.splitext(filename)[1].lower(),\n",
    "                        modified_time=os.path.getmtime(full_path)\n",
    "                    )\n",
    "                    all_files.append(file_info)\n",
    "                except OSError as e:\n",
    "                    print(f\"Ошибка доступа к файлу {full_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обхода директории: {e}\")\n",
    "\n",
    "    extension_counter = Counter(f.extension for f in all_files)\n",
    "\n",
    "    size_groups = defaultdict(list)\n",
    "    for file in all_files:\n",
    "        if file.size < 1024 * 1024:\n",
    "            size_groups['small'].append(file)\n",
    "        elif file.size < 100 * 1024 * 1024:\n",
    "            size_groups['medium'].append(file)\n",
    "        else:\n",
    "            size_groups['large'].append(file)\n",
    "\n",
    "    last_files = deque(all_files[-10:], maxlen=10)  # последние 10 файлов\n",
    "\n",
    "    return {\n",
    "        'all_files': all_files,\n",
    "        'extension_counter': extension_counter,\n",
    "        'size_groups': size_groups,\n",
    "        'last_files': last_files\n",
    "    }\n",
    "\n",
    "def save_analysis(data: Dict[str, Any], filename: str) -> None:\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json_data = {\n",
    "                'all_files': [f._asdict() for f in data['all_files']],\n",
    "                'extension_counter': dict(data['extension_counter']),\n",
    "                'size_groups': {k: [f._asdict() for f in v] for k, v in data['size_groups'].items()},\n",
    "                'last_files': [f._asdict() for f in data['last_files']]\n",
    "            }\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Анализ сохранен в {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка сохранения: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('gfhjk'):\n",
    "    result = analyze_directory(path)\n",
    "    save_analysis(result, 'file_analysis.json')\n",
    "else:\n",
    "    print(\"Указанный путь не существует.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Указанный путь не существует.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3: Система конфигурации приложения**\n",
    "\n",
    "Создайте систему конфигурации используя ChainMap и defaultdict:\n",
    "\n",
    "1. Создайте namedtuple `Config` с полями: key, value, section, default_value\n",
    "2. Создайте несколько словарей конфигурации (default, user, environment)\n",
    "3. Используйте `ChainMap` для объединения конфигураций с приоритетом\n",
    "4. Используйте `defaultdict(dict)` для группировки настроек по секциям\n",
    "5. Используйте `OrderedDict` для сохранения порядка загрузки конфигураций\n",
    "6. Используйте `os.environ` для чтения переменных окружения\n",
    "7. Сериализуйте конфигурацию в JSON и pickle форматы\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T22:15:08.663113Z",
     "start_time": "2025-09-24T22:15:08.637421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import ChainMap, defaultdict, OrderedDict\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, Any\n",
    "\n",
    "Config = namedtuple('Config', ['key', 'value', 'section', 'default_value'])\n",
    "\n",
    "def create_config_system() -> Dict[str, Any]:\n",
    "    default_config = {'theme': 'light', 'language': 'en'}\n",
    "    user_config = {'language': 'fr'}\n",
    "    env_config = {'theme': 'dark'}\n",
    "\n",
    "    configs = []\n",
    "    for key, value in default_config.items():\n",
    "        configs.append(Config(\n",
    "            key=key,\n",
    "            value=value,\n",
    "            section='general',\n",
    "            default_value=value\n",
    "        ))\n",
    "\n",
    "    for key, value in user_config.items():\n",
    "        configs.append(Config(\n",
    "            key=key,\n",
    "            value=value,  # новое значение пользователя\n",
    "            section='general',\n",
    "            default_value=default_config.get(key, 'NOT_SET')  # исходное значение\n",
    "        ))\n",
    "\n",
    "    # Для env конфигурации\n",
    "    for key, value in env_config.items():\n",
    "        configs.append(Config(\n",
    "            key=key,\n",
    "            value=value,  # значение из окружения\n",
    "            section='general',\n",
    "            default_value=default_config.get(key, 'NOT_SET')\n",
    "        ))\n",
    "\n",
    "    chain = ChainMap(env_config, user_config, default_config)\n",
    "\n",
    "\n",
    "    grouped_by_sections = defaultdict(list)\n",
    "    for config in configs:\n",
    "        grouped_by_sections[config.section].append(config)\n",
    "\n",
    "    ordered_configs = OrderedDict()\n",
    "    ordered_configs['env'] = env_config\n",
    "    ordered_configs['user'] = user_config\n",
    "    ordered_configs['default'] = default_config\n",
    "\n",
    "    return {\n",
    "        'config_objects': configs,  # ТУТ ХРАНЯТСЯ NAMEDTUPLE\n",
    "        'chain': chain,\n",
    "        'grouped_by_sections': grouped_by_sections,\n",
    "        'ordered_configs': ordered_configs\n",
    "    }\n",
    "\n",
    "def save_configs(data: Dict[str, Any]) -> None:\n",
    "    try:\n",
    "        with open('config.json', 'w', encoding='utf-8') as f:\n",
    "            json_data = {\n",
    "                'config_objects': [c._asdict() for c in data['config_objects']],  # namedtuple → dict\n",
    "                'chain': dict(data['chain']),\n",
    "                'grouped_by_sections': {\n",
    "                    section: [c._asdict() for c in configs]\n",
    "                    for section, configs in data['grouped_by_sections'].items()\n",
    "                },\n",
    "                'ordered_configs': dict(data['ordered_configs'])\n",
    "            }\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "        print(\"Конфиги сохранены в config.json\")\n",
    "\n",
    "        with open('config.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(\"Конфиги сохранены в config.pkl\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка сохранения: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    configs = create_config_system()\n",
    "    save_configs(configs)\n",
    "\n",
    "    print(\"\\n=== Демонстрация namedtuple ===\")\n",
    "    for config in configs['config_objects']:\n",
    "        print(f\"Ключ: {config.key}, Значение: {config.value}, Секция: {config.section}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конфиги сохранены в config.json\n",
      "Конфиги сохранены в config.pkl\n",
      "\n",
      "=== Демонстрация namedtuple ===\n",
      "Ключ: theme, Значение: light, Секция: general\n",
      "Ключ: language, Значение: en, Секция: general\n",
      "Ключ: language, Значение: fr, Секция: general\n",
      "Ключ: theme, Значение: dark, Секция: general\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 4: Мониторинг системы**\n",
    "\n",
    "Создайте систему мониторинга используя sys и os:\n",
    "\n",
    "1. Создайте namedtuple `SystemInfo` с полями: cpu_count, memory_usage, process_id, user_name\n",
    "2. Используйте `os.cpu_count()` для получения количества процессоров\n",
    "3. Используйте `sys.getallocatedblocks()` для мониторинга памяти\n",
    "4. Используйте `os.getpid()` и `os.getlogin()` для информации о процессе\n",
    "5. Используйте `deque` для хранения последних 20 измерений\n",
    "6. Используйте `Counter` для подсчета частоты использования различных функций\n",
    "7. Используйте `defaultdict(list)` для группировки измерений по времени\n",
    "8. Сохраните историю мониторинга в pickle файл\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T22:16:14.051024Z",
     "start_time": "2025-09-24T22:16:08.891845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from collections import namedtuple, deque, defaultdict, Counter\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "SystemInfo = namedtuple('SystemInfo', ['cpu_count', 'memory_usage', 'process_id', 'user_name'])\n",
    "\n",
    "def collect_system_info() -> SystemInfo:\n",
    "    return SystemInfo(\n",
    "        cpu_count=os.cpu_count(),\n",
    "        memory_usage=sys.getallocatedblocks(),\n",
    "        process_id=os.getpid(),\n",
    "        user_name=os.getlogin()\n",
    "    )\n",
    "\n",
    "def monitor_system(interval: float = 1.0, count: int = 5) -> Dict[str, Any]:\n",
    "    measurements = deque(maxlen=20)\n",
    "    by_time = defaultdict(list)\n",
    "    func_counter = Counter()\n",
    "\n",
    "    for _ in range(count):\n",
    "        info = collect_system_info()\n",
    "        measurements.append(info)\n",
    "        by_time[time.time()].append(info)\n",
    "        func_counter['measurement'] += 1\n",
    "        time.sleep(interval)\n",
    "        func_counter['sleep'] += 1\n",
    "\n",
    "    return {\n",
    "        'measurements': measurements,\n",
    "        'by_time': by_time,\n",
    "        'func_counter': func_counter\n",
    "    }\n",
    "\n",
    "def save_monitoring_data(data: Dict[str, Any], filename: str) -> None:\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"Данные мониторинга сохранены в {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка сохранения: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = monitor_system()\n",
    "    save_monitoring_data(data, 'monitoring.pkl')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные мониторинга сохранены в monitoring.pkl\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 5: Система логирования**\n",
    "\n",
    "Создайте систему логирования используя все изученные коллекции:\n",
    "\n",
    "1. Создайте namedtuple `LogEntry` с полями: timestamp, level, message, module, function\n",
    "2. Используйте `deque` для хранения последних 100 логов (кольцевой буфер)\n",
    "3. Используйте `defaultdict(list)` для группировки логов по уровням (DEBUG, INFO, WARNING, ERROR)\n",
    "4. Используйте `Counter` для подсчета количества логов каждого уровня\n",
    "5. Используйте `OrderedDict` для хранения логов по времени (FIFO)\n",
    "6. Используйте `ChainMap` для объединения различных источников логов\n",
    "7. Используйте `os.path` для работы с файлами логов\n",
    "8. Сериализуйте логи в JSON и pickle форматы\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T19:25:50.336394Z",
     "start_time": "2025-09-14T19:25:50.309412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from collections import namedtuple, deque, defaultdict, Counter, OrderedDict, ChainMap\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "LogEntry = namedtuple('LogEntry', ['timestamp', 'level', 'message', 'module', 'function'])\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, maxlen: int = 100):\n",
    "        self.buffer = deque(maxlen=maxlen)\n",
    "        self.by_level = defaultdict(list)\n",
    "        self.counter = Counter()\n",
    "        self.by_time = OrderedDict()\n",
    "\n",
    "    def log(self, level: str, message: str, module: str, function: str):\n",
    "        entry = LogEntry(time.time(), level, message, module, function)\n",
    "        self.buffer.append(entry)\n",
    "        self.by_level[level].append(entry)\n",
    "        self.counter[level] += 1\n",
    "        self.by_time[entry.timestamp] = entry\n",
    "\n",
    "    def save_logs(self, base_filename: str):\n",
    "        os.makedirs('logs', exist_ok=True)\n",
    "        json_path = os.path.join('logs', f'{base_filename}.json')\n",
    "        pkl_path = os.path.join('logs', f'{base_filename}.pkl')\n",
    "\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([e._asdict() for e in self.buffer], f, indent=4)\n",
    "\n",
    "        with open(pkl_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'buffer': list(self.buffer),\n",
    "                'by_level': dict(self.by_level),\n",
    "                'counter': dict(self.counter),\n",
    "                'by_time': dict(self.by_time)\n",
    "            }, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger = Logger()\n",
    "    logger.log('INFO', 'Запуск системы', 'main', 'start')\n",
    "    logger.log('ERROR', 'Ошибка загрузки', 'auth', 'login')\n",
    "    logger.save_logs('app_logs')"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 6: Кэш-система**\n",
    "\n",
    "Создайте простую кэш-систему используя collections:\n",
    "\n",
    "1. Создайте namedtuple `CacheEntry` с полями: key, value, timestamp, access_count\n",
    "2. Используйте `OrderedDict` для реализации LRU (Least Recently Used) кэша\n",
    "3. Используйте `deque` для хранения истории доступа к ключам\n",
    "4. Используйте `Counter` для подсчета частоты доступа к каждому ключу\n",
    "5. Используйте `defaultdict(int)` для хранения счетчиков доступа\n",
    "6. Реализуйте методы: get, set, delete, clear, size\n",
    "7. Используйте `sys.getsizeof()` для мониторинга размера кэша\n",
    "8. Сериализуйте кэш в pickle формат для сохранения между сессиями\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T22:31:18.248293Z",
     "start_time": "2025-09-24T22:31:18.221663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import OrderedDict, deque, Counter, defaultdict\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Any, Optional\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.cache: OrderedDict[Any, Any] = OrderedDict()\n",
    "        self.history = deque(maxlen=100)\n",
    "        self.access_count = Counter()\n",
    "        self.size_counter = defaultdict(int)\n",
    "\n",
    "    def get(self, key: Any) -> Optional[Any]:\n",
    "        if key not in self.cache:\n",
    "            return None\n",
    "        self.cache.move_to_end(key)\n",
    "        self.history.append(key)\n",
    "        self.access_count[key] += 1\n",
    "        return self.cache[key]\n",
    "\n",
    "    def set(self, key: Any, value: Any): #добавление значения\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "        self.cache[key] = value\n",
    "        self.history.append(key)\n",
    "        if len(self.cache) > self.capacity:\n",
    "            self.cache.popitem(last=False)\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.cache, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    c = LRUCache(2)\n",
    "    c.set('a', 1)\n",
    "    c.set('b', 2)\n",
    "    c.save('cache.pkl')\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 7: Анализатор текста**\n",
    "\n",
    "Создайте анализатор текста используя collections:\n",
    "\n",
    "1. Создайте namedtuple `WordInfo` с полями: word, frequency, length, first_occurrence\n",
    "2. Используйте `Counter` для подсчета частоты слов\n",
    "3. Используйте `defaultdict(list)` для группировки слов по длине\n",
    "4. Используйте `deque` для хранения последних 50 уникальных слов\n",
    "5. Используйте `OrderedDict` для хранения слов в порядке первого появления\n",
    "6. Используйте `os.path` для работы с текстовыми файлами\n",
    "7. Используйте `sys.getsizeof()` для анализа памяти\n",
    "8. Сохраните результаты анализа в JSON файл\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:28:30.612487Z",
     "start_time": "2025-09-24T13:28:30.531211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter, defaultdict, deque, OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def analyze_text(filepath: str) -> Dict[str, Any]:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    words = text.lower().split()\n",
    "    word_counter = Counter(words)\n",
    "\n",
    "    by_length = defaultdict(list)\n",
    "    for word in words:\n",
    "        by_length[len(word)].append(word)\n",
    "\n",
    "    last_unique = deque(word_counter.keys(), maxlen=50)\n",
    "\n",
    "    first_occurrence = OrderedDict()\n",
    "    for i, word in enumerate(words):#пары индекс и элемент, то есть номер слова и само слово\n",
    "        if word not in first_occurrence:\n",
    "            first_occurrence[word] = i #первое появление слова\n",
    "\n",
    "    return {\n",
    "        'word_counter': word_counter,\n",
    "        'by_length': by_length,\n",
    "        'last_unique': last_unique,\n",
    "        'first_occurrence': first_occurrence\n",
    "    }\n",
    "\n",
    "def save_analysis(data: Dict[str, Any], filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'word_counter': dict(data['word_counter']),\n",
    "            'by_length': {k: v for k, v in data['by_length'].items()},\n",
    "            'last_unique': list(data['last_unique']),\n",
    "            'first_occurrence': dict(data['first_occurrence'])\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = analyze_text('sample.txt')\n",
    "    save_analysis(result, 'text_analysis.json')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ завершен успешно!\n",
      "Уникальных слов: 11\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 8: Система управления задачами**\n",
    "\n",
    "Создайте систему управления задачами (TODO) используя все изученные концепции:\n",
    "\n",
    "1. Создайте namedtuple `Task` с полями: id, title, description, priority, status, created_date\n",
    "2. Используйте `defaultdict(list)` для группировки задач по статусу (todo, in_progress, done)\n",
    "3. Используйте `deque` для очереди задач с высоким приоритетом\n",
    "4. Используйте `Counter` для подсчета задач по приоритету\n",
    "5. Используйте `OrderedDict` для хранения задач в порядке создания\n",
    "6. Используйте `ChainMap` для объединения различных списков задач\n",
    "7. Используйте `os.path` для работы с файлами задач\n",
    "8. Реализуйте функции: add_task, complete_task, get_tasks_by_status, get_priority_queue\n",
    "9. Сериализуйте все данные в JSON и pickle форматы\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T22:38:29.810875Z",
     "start_time": "2025-09-24T22:38:29.773296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict, deque, OrderedDict, ChainMap, Counter\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "Task = namedtuple('Task', ['id', 'title', 'description', 'priority', 'status', 'created_at'])\n",
    "\n",
    "class TaskManager:\n",
    "    def __init__(self):\n",
    "        self.tasks = OrderedDict()\n",
    "        self.by_status = defaultdict(list)\n",
    "        self.high_priority_queue = deque()\n",
    "        self.priority_counter = Counter()\n",
    "\n",
    "    def add_task(self, task: Task):\n",
    "        self.tasks[task.id] = task\n",
    "        self.by_status[task.status].append(task)\n",
    "        if task.priority == 3:\n",
    "            self.high_priority_queue.append(task)\n",
    "        self.priority_counter[task.priority] += 1\n",
    "\n",
    "    def complete_task(self, task_id: int):\n",
    "        if task_id in self.tasks:\n",
    "            task = self.tasks[task_id]\n",
    "            new_task = task._replace(status='done')\n",
    "            self.tasks[task_id] = new_task\n",
    "            self.by_status[task.status].remove(task)\n",
    "            self.by_status['done'].append(new_task)\n",
    "\n",
    "    def save(self, base_name: str):\n",
    "        with open(f'{base_name}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump([t._asdict() for t in self.tasks.values()], f, indent=4, default=str)\n",
    "\n",
    "        with open(f'{base_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.tasks, f)\n",
    "\n",
    "tm = TaskManager()\n",
    "tm.add_task(Task(1, 'Задача 1', 'Описание', 3, 'todo', datetime.now()))\n",
    "tm.save('tasks')"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 9: Система мониторинга производительности**\n",
    "\n",
    "Создайте систему мониторинга производительности используя sys и collections:\n",
    "\n",
    "1. Создайте namedtuple `PerformanceMetric` с полями: function_name, execution_time, memory_usage, timestamp\n",
    "2. Используйте `deque` для хранения последних 100 измерений производительности\n",
    "3. Используйте `defaultdict(list)` для группировки метрик по функциям\n",
    "4. Используйте `Counter` для подсчета количества вызовов каждой функции\n",
    "5. Используйте `OrderedDict` для хранения метрик в хронологическом порядке\n",
    "6. Используйте `sys.getsizeof()` для мониторинга памяти\n",
    "7. Используйте `os.path` для работы с файлами метрик\n",
    "8. Реализуйте функции: record_metric, get_function_stats, get_memory_usage, export_metrics\n",
    "9. Сериализуйте метрики в JSON и pickle форматы\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T21:23:17.253738Z",
     "start_time": "2025-09-24T21:23:17.226401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import namedtuple, deque, defaultdict, Counter, OrderedDict\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# 1. NamedTuple для метрик (как требуется в задании)\n",
    "PerformanceMetric = namedtuple('PerformanceMetric', ['function_name', 'execution_time', 'memory_usage', 'timestamp'])\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        # 2. Deque для последних 100 измерений\n",
    "        self.last_metrics: deque[PerformanceMetric] = deque(maxlen=100)\n",
    "\n",
    "        # 3. DefaultDict для группировки по функциям\n",
    "        self.metrics_by_function: defaultdict[str, List[PerformanceMetric]] = defaultdict(list)\n",
    "\n",
    "        # 4. Counter для подсчета вызовов\n",
    "        self.function_call_counter: Counter[str] = Counter()\n",
    "\n",
    "        # 5. OrderedDict для хронологического порядка\n",
    "        self.metrics_ordered: OrderedDict[float, PerformanceMetric] = OrderedDict()\n",
    "\n",
    "    def record_metric(self, function_name: str, execution_time: float, memory_usage: int = 0) -> None:\n",
    "        \"\"\"Записывает метрику производительности\"\"\"\n",
    "        timestamp = time.time()\n",
    "        metric = PerformanceMetric(function_name, execution_time, memory_usage, timestamp)\n",
    "\n",
    "        # Сохраняем во все структуры\n",
    "        self.last_metrics.append(metric)\n",
    "        self.metrics_by_function[function_name].append(metric)\n",
    "        self.function_call_counter[function_name] += 1\n",
    "        self.metrics_ordered[timestamp] = metric\n",
    "\n",
    "    def get_function_stats(self, function_name: str) -> Dict[str, float]:\n",
    "        \"\"\"Возвращает статистику по функции\"\"\"\n",
    "        metrics = self.metrics_by_function.get(function_name, [])\n",
    "        count = len(metrics)\n",
    "        if count == 0:\n",
    "            return {'count': 0, 'average_time': 0, 'total_memory': 0}\n",
    "\n",
    "        avg_time = sum(m.execution_time for m in metrics) / count\n",
    "        total_memory = sum(m.memory_usage for m in metrics)\n",
    "\n",
    "        return {'count': count, 'average_time': avg_time, 'total_memory': total_memory}\n",
    "\n",
    "    def get_memory_usage(self, function_name: str) -> int:\n",
    "        \"\"\"Возвращает общее использование памяти для функции\"\"\"\n",
    "        metrics = self.metrics_by_function.get(function_name, [])\n",
    "        return sum(m.memory_usage for m in metrics)\n",
    "\n",
    "    def export_metrics(self, filename: str) -> None:\n",
    "        \"\"\"Экспортирует метрики в JSON и pickle\"\"\"\n",
    "        # JSON экспорт\n",
    "        json_filename = os.path.splitext(filename)[0] + '.json'\n",
    "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "            json_data = [\n",
    "                {\n",
    "                    'function_name': m.function_name,\n",
    "                    'execution_time': m.execution_time,\n",
    "                    'memory_usage': m.memory_usage,\n",
    "                    'timestamp': m.timestamp\n",
    "                }\n",
    "                for m in self.metrics_ordered.values()\n",
    "            ]\n",
    "            json.dump(json_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        # Pickle экспорт\n",
    "        pickle_filename = os.path.splitext(filename)[0] + '.pkl'\n",
    "        with open(pickle_filename, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'last_metrics': list(self.last_metrics),\n",
    "                'metrics_by_function': dict(self.metrics_by_function),\n",
    "                'function_call_counter': dict(self.function_call_counter),\n",
    "                'metrics_ordered': dict(self.metrics_ordered)\n",
    "            }, f)\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    monitor = PerformanceMonitor()\n",
    "\n",
    "    # Симуляция измерения производительности\n",
    "    monitor.record_metric('calculate_sum', 0.15, 1024)\n",
    "    monitor.record_metric('process_data', 0.23, 2048)\n",
    "    monitor.record_metric('calculate_sum', 0.18, 1024)\n",
    "\n",
    "    # Получение статистики\n",
    "    stats = monitor.get_function_stats('calculate_sum')\n",
    "    print(f\"Статистика calculate_sum: {stats}\")\n",
    "\n",
    "    # Экспорт метрик\n",
    "    monitor.export_metrics('performance_metrics')"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 10: Комплексная система управления данными**\n",
    "\n",
    "Создайте комплексную систему управления данными, объединяющую все изученные концепции:\n",
    "\n",
    "1. Создайте несколько namedtuple для различных типов данных (User, Product, Order, etc.)\n",
    "2. Используйте `defaultdict` для создания индексов по различным полям\n",
    "3. Используйте `deque` для реализации очередей обработки данных\n",
    "4. Используйте `Counter` для аналитики и статистики\n",
    "5. Используйте `OrderedDict` для хранения данных в определенном порядке\n",
    "6. Используйте `ChainMap` для объединения различных источников данных\n",
    "7. Используйте `os` и `sys` для работы с файловой системой и мониторинга\n",
    "8. Реализуйте CRUD операции (Create, Read, Update, Delete)\n",
    "9. Добавьте функции экспорта/импорта данных в различных форматах\n",
    "10. Сериализуйте все данные в JSON, pickle и другие форматы\n",
    "11. Добавьте типизацию для всех функций и классов\n",
    "12. Реализуйте систему логирования для отслеживания операций\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T21:27:43.673194Z",
     "start_time": "2025-09-24T21:27:43.603135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import namedtuple, defaultdict, deque, Counter, OrderedDict, ChainMap\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Dict, Optional, Any\n",
    "import logging\n",
    "\n",
    "# === Настройка логирования ===\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', #Формат лога: 2024-01-01 12:00:00 - INFO - Сообщение\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"data_system.log\"),\n",
    "        logging.StreamHandler() # рбработчики логов, запись в файл и вывод в консоль\n",
    "    ]\n",
    ")\n",
    "\n",
    "# === NamedTuple для различных данных ===\n",
    "User = namedtuple('User', ['id', 'name', 'email', 'created_at'])\n",
    "Product = namedtuple('Product', ['id', 'name', 'price', 'created_at'])\n",
    "Order = namedtuple('Order', ['id', 'user_id', 'product_id', 'quantity', 'created_at'])\n",
    "\n",
    "# === Основные структуры данных ===\n",
    "users_ordered: OrderedDict[int, User] = OrderedDict()\n",
    "products_ordered: OrderedDict[int, Product] = OrderedDict()\n",
    "orders_ordered: OrderedDict[int, Order] = OrderedDict()\n",
    "\n",
    "# Индексы по полям для быстрого поиска\n",
    "users_by_email: defaultdict[str, list[User]] = defaultdict(list)\n",
    "products_by_name: defaultdict[str, list[Product]] = defaultdict(list)\n",
    "orders_by_user: defaultdict[int, list[Order]] = defaultdict(list)\n",
    "\n",
    "# Очереди для обработки данных\n",
    "user_queue: deque[User] = deque()\n",
    "order_queue: deque[Order] = deque()\n",
    "\n",
    "# Статистика\n",
    "product_order_counter: Counter[int] = Counter()\n",
    "user_order_counter: Counter[int] = Counter()\n",
    "\n",
    "# ChainMap для объединения всех источников данных\n",
    "all_data: ChainMap = ChainMap(users_ordered, products_ordered, orders_ordered)\n",
    "\n",
    "# === CRUD операции ===\n",
    "def create_user(user_id: int, name: str, email: str) -> User:\n",
    "    user = User(user_id, name, email, datetime.now())\n",
    "    users_ordered[user_id] = user\n",
    "    users_by_email[email].append(user)\n",
    "    user_queue.append(user)\n",
    "    logging.info(f\"User created: {user}\")\n",
    "    return user\n",
    "\n",
    "def read_user(user_id: int) -> Optional[User]:\n",
    "    return users_ordered.get(user_id)\n",
    "\n",
    "def update_user(user_id: int, name: Optional[str] = None, email: Optional[str] = None) -> Optional[User]:\n",
    "    user = users_ordered.get(user_id)\n",
    "    if not user:\n",
    "        return None\n",
    "    new_user = User(\n",
    "        id=user.id,\n",
    "        name=name if name else user.name,\n",
    "        email=email if email else user.email,\n",
    "        created_at=user.created_at\n",
    "    )\n",
    "    users_ordered[user_id] = new_user\n",
    "    if email:\n",
    "        users_by_email[email].append(new_user)\n",
    "    logging.info(f\"User updated: {new_user}\")\n",
    "    return new_user\n",
    "\n",
    "def delete_user(user_id: int) -> bool:\n",
    "    user = users_ordered.pop(user_id, None)\n",
    "    if user:\n",
    "        users_by_email[user.email].remove(user)\n",
    "        logging.info(f\"User deleted: {user}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def create_product(product_id: int, name: str, price: float) -> Product:\n",
    "    product = Product(product_id, name, price, datetime.now())\n",
    "    products_ordered[product_id] = product\n",
    "    products_by_name[name].append(product)\n",
    "    logging.info(f\"Product created: {product}\")\n",
    "    return product\n",
    "\n",
    "def create_order(order_id: int, user_id: int, product_id: int, quantity: int) -> Order:\n",
    "    order = Order(order_id, user_id, product_id, quantity, datetime.now())\n",
    "    orders_ordered[order_id] = order\n",
    "    orders_by_user[user_id].append(order)\n",
    "    order_queue.append(order)\n",
    "    product_order_counter[product_id] += quantity\n",
    "    user_order_counter[user_id] += 1\n",
    "    logging.info(f\"Order created: {order}\")\n",
    "    return order\n",
    "\n",
    "\n",
    "def save_data_json(filename: str) -> None:\n",
    "    data = {\n",
    "        'users': [u._asdict() for u in users_ordered.values()],\n",
    "        'products': [p._asdict() for p in products_ordered.values()],\n",
    "        'orders': [o._asdict() for o in orders_ordered.values()]\n",
    "    }\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4, default=str)\n",
    "    logging.info(f\"Data saved to JSON: {filename}\")\n",
    "\n",
    "def save_data_pickle(filename: str) -> None:\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((users_ordered, products_ordered, orders_ordered), f)\n",
    "    logging.info(f\"Data saved to pickle: {filename}\")\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### РЕКОМЕНДАЦИИ ПО ВЫПОЛНЕНИЮ ЗАДАЧ\n",
    "\n",
    "1. **Начните с простых задач** (1-3) для понимания базовых концепций\n",
    "2. **Используйте типизацию** - добавляйте type hints для всех функций и переменных\n",
    "3. **Структурируйте код** - разбивайте задачи на логические функции и классы\n",
    "4. **Документируйте код** - добавляйте docstrings для всех функций\n",
    "5. **Тестируйте сериализацию** - убедитесь, что данные корректно сохраняются и загружаются\n",
    "6. **Обрабатывайте ошибки** - используйте try-except блоки для обработки исключений\n",
    "7. **Оптимизируйте память** - используйте `sys.getsizeof()` для мониторинга использования памяти\n",
    "8. **Следуйте принципам** - код должен быть читаемым, понятным и структурированным\n",
    "\n",
    "**Дополнительные требования:**\n",
    "- Все объекты должны быть сериализованы в соответствующие форматы\n",
    "- Код должен содержать комментарии на русском языке\n",
    "- Функции должны быть небольшими и выполнять одну задачу\n",
    "- Используйте только те библиотеки и концепции, которые представлены в уроке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
